{
    "500": {
        "file_id": 10,
        "content": "        # if learning the variance, also include the extra weight kl loss\n        true_mean, _, true_log_variance_clipped = noise_scheduler.q_posterior(x_start = x_start, x_t = x_noisy, t = times)\n        model_mean, _, model_log_variance, _ = self.p_mean_variance(unet, x = x_noisy, t = times, image_embed = image_embed, noise_scheduler = noise_scheduler, clip_denoised = clip_denoised, learned_variance = True, model_output = unet_output)\n        # kl loss with detached model predicted mean, for stability reasons as in paper\n        detached_model_mean = model_mean.detach()\n        kl = normal_kl(true_mean, true_log_variance_clipped, detached_model_mean, model_log_variance)\n        kl = meanflat(kl) * NAT\n        decoder_nll = -discretized_gaussian_log_likelihood(x_start, means = detached_model_mean, log_scales = 0.5 * model_log_variance)\n        decoder_nll = meanflat(decoder_nll) * NAT\n        # at the first timestep return the decoder NLL, otherwise return KL(q(x_{t-1}|x_t,x_0) || p(x_{t-1}|x_t))",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3100-3115"
    },
    "501": {
        "file_id": 10,
        "content": "This code calculates the KL divergence between true and model predicted posterior distributions, and decoder negative log likelihood. It uses detached model predictions for stability reasons as per the paper. The loss at the first timestep is the decoder NLL, otherwise it's the KL divergence.",
        "type": "comment"
    },
    "502": {
        "file_id": 10,
        "content": "        vb_losses = torch.where(times == 0, decoder_nll, kl)\n        # weight the vb loss smaller, for stability, as in the paper (recommended 0.001)\n        vb_loss = vb_losses.mean() * self.vb_loss_weight\n        return loss + vb_loss\n    @torch.no_grad()\n    @eval_decorator\n    def sample(\n        self,\n        image = None,\n        image_embed = None,\n        text = None,\n        text_encodings = None,\n        batch_size = 1,\n        cond_scale = 1.,\n        start_at_unet_number = 1,\n        stop_at_unet_number = None,\n        distributed = False,\n        inpaint_image = None,\n        inpaint_mask = None,\n        inpaint_resample_times = 5,\n        one_unet_in_gpu_at_time = True\n    ):\n        assert self.unconditional or exists(image_embed), 'image embed must be present on sampling from decoder unless if trained unconditionally'\n        if not self.unconditional:\n            batch_size = image_embed.shape[0]\n        if exists(text) and not exists(text_encodings) and not self.unconditional:\n            assert exists(self.clip)",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3117-3149"
    },
    "503": {
        "file_id": 10,
        "content": "This function calculates the variational Bayes loss and adds it to the main loss. It then samples from the model given input parameters such as image, text, batch size, etc., with option for conditional or unconditional sampling. The function also performs some assertions on the inputs to ensure proper usage.",
        "type": "comment"
    },
    "504": {
        "file_id": 10,
        "content": "            _, text_encodings = self.clip.embed_text(text)\n        assert not (self.condition_on_text_encodings and not exists(text_encodings)), 'text or text encodings must be passed into decoder if specified'\n        assert not (not self.condition_on_text_encodings and exists(text_encodings)), 'decoder specified not to be conditioned on text, yet it is presented'\n        assert not (exists(inpaint_image) ^ exists(inpaint_mask)), 'inpaint_image and inpaint_mask (boolean mask of [batch, height, width]) must be both given for inpainting'\n        img = None\n        if start_at_unet_number > 1:\n            # Then we are not generating the first image and one must have been passed in\n            assert exists(image), 'image must be passed in if starting at unet number > 1'\n            assert image.shape[0] == batch_size, 'image must have batch size of {} if starting at unet number > 1'.format(batch_size)\n            prev_unet_output_size = self.image_sizes[start_at_unet_number - 2]\n            img = resize_image_to(image, prev_unet_output_size, nearest = True)",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3150-3163"
    },
    "505": {
        "file_id": 10,
        "content": "This code checks for valid inputs and asserts whether text, text encodings, or inpaint_image and mask are present based on the condition specified. It also ensures that the image input has the correct batch size when starting at a specific unet number. If necessary, it resizes the image using nearest-neighbor interpolation.",
        "type": "comment"
    },
    "506": {
        "file_id": 10,
        "content": "        is_cuda = next(self.parameters()).is_cuda\n        num_unets = self.num_unets\n        cond_scale = cast_tuple(cond_scale, num_unets)\n        for unet_number, unet, vae, channel, image_size, predict_x_start, predict_v, learned_variance, noise_scheduler, lowres_cond, sample_timesteps, unet_cond_scale in tqdm(zip(range(1, num_unets + 1), self.unets, self.vaes, self.sample_channels, self.image_sizes, self.predict_x_start, self.predict_v, self.learned_variance, self.noise_schedulers, self.lowres_conds, self.sample_timesteps, cond_scale)):\n            if unet_number < start_at_unet_number:\n                continue  # It's the easiest way to do it\n            context = self.one_unet_in_gpu(unet = unet) if is_cuda and one_unet_in_gpu_at_time else null_context()\n            with context:\n                # prepare low resolution conditioning for upsamplers\n                lowres_cond_img = lowres_noise_level = None\n                shape = (batch_size, channel, image_size, image_size)\n                if unet.lowres_cond:",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3165-3182"
    },
    "507": {
        "file_id": 10,
        "content": "This code is iterating through each unet in the model, skipping the first X unets based on a given parameter. It checks if the current unet should be processed based on its position, and then prepares low resolution conditioning for upsamplers if required. The code also handles CUDA processing and uses context managers to ensure efficient resource usage.",
        "type": "comment"
    },
    "508": {
        "file_id": 10,
        "content": "                    lowres_cond_img = resize_image_to(img, target_image_size = image_size, clamp_range = self.input_image_range, nearest = True)\n                    if lowres_cond.use_noise:\n                        lowres_noise_level = torch.full((batch_size,), int(self.lowres_noise_sample_level * 1000), dtype = torch.long, device = self.device)\n                        lowres_cond_img, _ = lowres_cond.noise_image(lowres_cond_img, lowres_noise_level)\n                # latent diffusion\n                is_latent_diffusion = isinstance(vae, VQGanVAE)\n                image_size = vae.get_encoded_fmap_size(image_size)\n                shape = (batch_size, vae.encoded_dim, image_size, image_size)\n                lowres_cond_img = maybe(vae.encode)(lowres_cond_img)\n                # denoising loop for image\n                img = self.p_sample_loop(\n                    unet,\n                    shape,\n                    image_embed = image_embed,\n                    text_encodings = text_encodings,\n                    cond_scale = unet_cond_scale,",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3183-3204"
    },
    "509": {
        "file_id": 10,
        "content": "This code is part of a denoising diffusion model. It first resizes the input image to a target size and applies noise if needed. Then, it checks if the VAE (Variational Autoencoder) is used for latent diffusion and adjusts the image size accordingly. Finally, it encodes the low-resolution image using the VAE and enters a denoising loop with a UNet model to generate the final output image.",
        "type": "comment"
    },
    "510": {
        "file_id": 10,
        "content": "                    predict_x_start = predict_x_start,\n                    predict_v = predict_v,\n                    learned_variance = learned_variance,\n                    clip_denoised = not is_latent_diffusion,\n                    lowres_cond_img = lowres_cond_img,\n                    lowres_noise_level = lowres_noise_level,\n                    is_latent_diffusion = is_latent_diffusion,\n                    noise_scheduler = noise_scheduler,\n                    timesteps = sample_timesteps,\n                    inpaint_image = inpaint_image,\n                    inpaint_mask = inpaint_mask,\n                    inpaint_resample_times = inpaint_resample_times\n                )\n                img = vae.decode(img)\n            if exists(stop_at_unet_number) and stop_at_unet_number == unet_number:\n                break\n        return img\n    def forward(\n        self,\n        image,\n        text = None,\n        image_embed = None,\n        text_encodings = None,\n        unet_number = None,\n        return_lowres_",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3205-3233"
    },
    "511": {
        "file_id": 10,
        "content": "The function takes an image and optionally text, generates images at different UNet resolutions based on input parameters, and returns the generated image. It includes options for low-resolution output, inpainting, and stopping at a specific UNet resolution.",
        "type": "comment"
    },
    "512": {
        "file_id": 10,
        "content": "cond_image = False # whether to return the low resolution conditioning images, for debugging upsampler purposes\n    ):\n        assert not (self.num_unets > 1 and not exists(unet_number)), f'you must specify which unet you want trained, from a range of 1 to {self.num_unets}, if you are training cascading DDPM (multiple unets)'\n        unet_number = default(unet_number, 1)\n        unet_index = unet_number - 1\n        unet = self.get_unet(unet_number)\n        vae                 = self.vaes[unet_index]\n        noise_scheduler     = self.noise_schedulers[unet_index]\n        lowres_conditioner  = self.lowres_conds[unet_index]\n        target_image_size   = self.image_sizes[unet_index]\n        predict_x_start     = self.predict_x_start[unet_index]\n        predict_v           = self.predict_v[unet_index]\n        random_crop_size    = self.random_crop_sizes[unet_index]\n        learned_variance    = self.learned_variance[unet_index]\n        b, c, h, w, device, = *image.shape, image.device\n        assert image.shape[1] == self.channels",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3233-3251"
    },
    "513": {
        "file_id": 10,
        "content": "This function is initializing variables for a specific U-Net in the model, based on the provided unet_number. It assigns the corresponding U-Net, VAE, noise scheduler, lowres conditioner, target image size, predict x start, predict v, random crop size, and learned variance from predefined lists for that U-Net index. It also ensures the image shape aligns with the expected number of channels.",
        "type": "comment"
    },
    "514": {
        "file_id": 10,
        "content": "        assert h >= target_image_size and w >= target_image_size\n        times = torch.randint(0, noise_scheduler.num_timesteps, (b,), device = device, dtype = torch.long)\n        if not exists(image_embed) and not self.unconditional:\n            assert exists(self.clip), 'if you want to derive CLIP image embeddings automatically, you must supply `clip` to the decoder on init'\n            image_embed, _ = self.clip.embed_image(image)\n        if exists(text) and not exists(text_encodings) and not self.unconditional:\n            assert exists(self.clip), 'if you are passing in raw text, you need to supply `clip` to the decoder'\n            _, text_encodings = self.clip.embed_text(text)\n        assert not (self.condition_on_text_encodings and not exists(text_encodings)), 'text or text encodings must be passed into decoder if specified'\n        assert not (not self.condition_on_text_encodings and exists(text_encodings)), 'decoder specified not to be conditioned on text, yet it is presented'\n        ",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3252-3267"
    },
    "515": {
        "file_id": 10,
        "content": "The code checks if the image and/or text inputs exist, ensuring that either the CLIP model or the necessary inputs are present. It asserts that if the decoder is supposed to be conditioned on text encodings, then the text encodings must be provided, and vice versa. This helps prevent errors in the input data for generating image embeddings.",
        "type": "comment"
    },
    "516": {
        "file_id": 10,
        "content": "lowres_cond_img, lowres_noise_level = lowres_conditioner(image, target_image_size = target_image_size, downsample_image_size = self.image_sizes[unet_index - 1]) if exists(lowres_conditioner) else (None, None)\n        image = resize_image_to(image, target_image_size, nearest = True)\n        if exists(random_crop_size):\n            aug = K.RandomCrop((random_crop_size, random_crop_size), p = 1.)\n            # make sure low res conditioner and image both get augmented the same way\n            # detailed https://kornia.readthedocs.io/en/latest/augmentation.module.html?highlight=randomcrop#kornia.augmentation.RandomCrop\n            image = aug(image)\n            lowres_cond_img = aug(lowres_cond_img, params = aug._params)\n        is_latent_diffusion = not isinstance(vae, NullVQGanVAE)\n        vae.eval()\n        with torch.no_grad():\n            image = vae.encode(image)\n            lowres_cond_img = maybe(vae.encode)(lowres_cond_img)\n        losses = self.p_losses(unet, image, times, image_embed = image",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3267-3285"
    },
    "517": {
        "file_id": 10,
        "content": "This code snippet is conditioning a low-resolution image using the lowres_conditioner and performing data augmentation via Kornia's RandomCrop. It also encodes both the image and the conditioned image using a VAE (Variational Autoencoder) and calculates loss from p_losses for further processing in the U-net model.",
        "type": "comment"
    },
    "518": {
        "file_id": 10,
        "content": "_embed, text_encodings = text_encodings, lowres_cond_img = lowres_cond_img, predict_x_start = predict_x_start, predict_v = predict_v, learned_variance = learned_variance, is_latent_diffusion = is_latent_diffusion, noise_scheduler = noise_scheduler, lowres_noise_level = lowres_noise_level)\n        if not return_lowres_cond_image:\n            return losses\n        return losses, lowres_cond_img\n# main class\nclass DALLE2(nn.Module):\n    def __init__(\n        self,\n        *,\n        prior,\n        decoder,\n        prior_num_samples = 2\n    ):\n        super().__init__()\n        assert isinstance(prior, DiffusionPrior)\n        assert isinstance(decoder, Decoder)\n        self.prior = prior\n        self.decoder = decoder\n        self.prior_num_samples = prior_num_samples\n        self.decoder_need_text_cond = self.decoder.condition_on_text_encodings\n        self.to_pil = T.ToPILImage()\n    @torch.no_grad()\n    @eval_decorator\n    def forward(\n        self,\n        text,\n        cond_scale = 1.,\n        prior_cond_scale = 1.,",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3285-3319"
    },
    "519": {
        "file_id": 10,
        "content": "This code defines a DALLE2 class with prior and decoder modules. It takes text input, performs diffusion, and returns losses or lowres_cond_img based on the return flag. If not returning the lowres conditional image, it returns only losses.",
        "type": "comment"
    },
    "520": {
        "file_id": 10,
        "content": "        return_pil_images = False\n    ):\n        device = module_device(self)\n        one_text = isinstance(text, str) or (not is_list_str(text) and text.shape[0] == 1)\n        if isinstance(text, str) or is_list_str(text):\n            text = [text] if not isinstance(text, (list, tuple)) else text\n            text = tokenizer.tokenize(text).to(device)\n        image_embed = self.prior.sample(text, num_samples_per_batch = self.prior_num_samples, cond_scale = prior_cond_scale)\n        text_cond = text if self.decoder_need_text_cond else None\n        images = self.decoder.sample(image_embed = image_embed, text = text_cond, cond_scale = cond_scale)\n        if return_pil_images:\n            images = list(map(self.to_pil, images.unbind(dim = 0)))\n        if one_text:\n            return first(images)\n        return images",
        "type": "code",
        "location": "/dalle2_pytorch/dalle2_pytorch.py:3320-3340"
    },
    "521": {
        "file_id": 10,
        "content": "This function takes text as input, tokenizes it if necessary, and uses a prior model to generate image embeddings. It then passes these embeddings along with the text (if required) to a decoder model to generate images. Optionally, it converts the images to PIL format and returns them. If only one text is given, it returns the first generated image.",
        "type": "comment"
    },
    "522": {
        "file_id": 11,
        "content": "/dalle2_pytorch/optimizer.py",
        "type": "filepath"
    },
    "523": {
        "file_id": 11,
        "content": "This code defines two functions, `separate_weight_decayable_params` and `get_optimizer`. The `get_optimizer` function takes parameters, learning rate, weight decay, and other options to create an optimizer object. It filters the parameters based on `requires_grad`, separates weight-decayable parameters, and uses either Adam or AdamW optimizer depending on the weight decay value.",
        "type": "summary"
    },
    "524": {
        "file_id": 11,
        "content": "from torch.optim import AdamW, Adam\ndef separate_weight_decayable_params(params):\n    wd_params, no_wd_params = [], []\n    for param in params:\n        param_list = no_wd_params if param.ndim < 2 else wd_params\n        param_list.append(param)\n    return wd_params, no_wd_params\ndef get_optimizer(\n    params,\n    lr = 1e-4,\n    wd = 1e-2,\n    betas = (0.9, 0.99),\n    eps = 1e-8,\n    filter_by_requires_grad = False,\n    group_wd_params = True,\n    **kwargs\n):\n    if filter_by_requires_grad:\n        params = list(filter(lambda t: t.requires_grad, params))\n    if wd == 0:\n        return Adam(params, lr = lr, betas = betas, eps = eps)\n    if group_wd_params:\n        wd_params, no_wd_params = separate_weight_decayable_params(params)\n        params = [\n            {'params': wd_params},\n            {'params': no_wd_params, 'weight_decay': 0},\n        ]\n    return AdamW(params, lr = lr, weight_decay = wd, betas = betas, eps = eps)",
        "type": "code",
        "location": "/dalle2_pytorch/optimizer.py:1-34"
    },
    "525": {
        "file_id": 11,
        "content": "This code defines two functions, `separate_weight_decayable_params` and `get_optimizer`. The `get_optimizer` function takes parameters, learning rate, weight decay, and other options to create an optimizer object. It filters the parameters based on `requires_grad`, separates weight-decayable parameters, and uses either Adam or AdamW optimizer depending on the weight decay value.",
        "type": "comment"
    },
    "526": {
        "file_id": 12,
        "content": "/dalle2_pytorch/tokenizer.py",
        "type": "filepath"
    },
    "527": {
        "file_id": 12,
        "content": "The code simplifies DALL-E2 text tokenization by offering a PyTorch BPE tokenizer implementation with features for whitespace cleanup, formatting fixes, human-readable conversion, and handling context length limitations.",
        "type": "summary"
    },
    "528": {
        "file_id": 12,
        "content": "# take from https://github.com/openai/CLIP/blob/main/clip/simple_tokenizer.py\n# to give users a quick easy start to training DALL-E without doing BPE\nimport torch\nimport html\nimport os\nimport ftfy\nimport regex as re\nfrom functools import lru_cache\nfrom pathlib import Path\nfrom dalle2_pytorch.utils import import_or_print_error\n# OpenAI simple tokenizer\n@lru_cache()\ndef default_bpe():\n    return os.path.join(os.path.dirname(os.path.abspath(__file__)), \"data/bpe_simple_vocab_16e6.txt\")\n@lru_cache()\ndef bytes_to_unicode():\n    bs = list(range(ord(\"!\"), ord(\"~\") + 1)) + list(range(ord(\"¡\"), ord(\"¬\") + 1)) + list(range(ord(\"®\"), ord(\"ÿ\") + 1))\n    cs = bs[:]\n    n = 0\n    for b in range(2 ** 8):\n        if b not in bs:\n            bs.append(b)\n            cs.append(2 ** 8 + n)\n            n += 1\n    cs = [chr(n) for n in cs]\n    return dict(zip(bs, cs))\ndef get_pairs(word):\n    pairs = set()\n    prev_char = word[0]\n    for char in word[1:]:\n        pairs.add((prev_char, char))\n        prev_char = char\n    return pairs\ndef basic_clean(text):",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:1-42"
    },
    "529": {
        "file_id": 12,
        "content": "This code imports necessary libraries and defines functions for tokenization, specifically for the DALL-E2 model. It uses OpenAI's simple tokenizer, a byte-to-unicode conversion, and a function to generate character pairs from a given word. The code is meant to provide users with an easy way to start training DALL-E without implementing BPE (Byte Pair Encoding).",
        "type": "comment"
    },
    "530": {
        "file_id": 12,
        "content": "    text = ftfy.fix_text(text)\n    text = html.unescape(html.unescape(text))\n    return text.strip()\ndef whitespace_clean(text):\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    return text\nclass SimpleTokenizer(object):\n    def __init__(self, bpe_path = default_bpe()):\n        self.byte_encoder = bytes_to_unicode()\n        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n        merges = Path(bpe_path).read_text(encoding='utf8').split('\\n')\n        merges = merges[1:49152 - 256 - 2 + 1]\n        merges = [tuple(merge.split()) for merge in merges]\n        vocab = list(bytes_to_unicode().values())\n        vocab = vocab + [v + '</w>' for v in vocab]\n        for merge in merges:\n            vocab.append(''.join(merge))\n        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n        self.vocab_size = 49408\n        self.encoder = dict(zip(vocab, range(len(vocab))))\n        self.decoder = {v: k for k, v in self.encoder.items()}\n        self.bpe_ranks = dict(zip(merges, range(len(merges))))",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:43-69"
    },
    "531": {
        "file_id": 12,
        "content": "This code is a Python class for a tokenizer that utilizes byte encoding and decoding, along with byte-pair encoding (BPE) to convert text into tokens. The class also includes methods for cleaning whitespace and fixing text formatting issues. The BPE merges are loaded from a specified file path, and the vocabulary is expanded by adding special tokens like \"<|startoftext|>\" and \"<|endoftext|>\".",
        "type": "comment"
    },
    "532": {
        "file_id": 12,
        "content": "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n        self.pat = re.compile(\n            r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\",\n            re.IGNORECASE)\n    def bpe(self, token):\n        if token in self.cache:\n            return self.cache[token]\n        word = tuple(token[:-1]) + (token[-1] + '</w>',)\n        pairs = get_pairs(word)\n        if not pairs:\n            return token + '</w>'\n        while True:\n            bigram = min(pairs, key=lambda pair: self.bpe_ranks.get(pair, float('inf')))\n            if bigram not in self.bpe_ranks:\n                break\n            first, second = bigram\n            new_word = []\n            i = 0\n            while i < len(word):\n                try:\n                    j = word.index(first, i)\n                    new_word.extend(word[i:j])\n                    i = j\n                except:\n                    new_word.extend(word[i:])\n                    break",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:70-98"
    },
    "533": {
        "file_id": 12,
        "content": "The code defines a tokenizer that uses byte-pair encoding (BPE) for text. It compiles a regular expression pattern to match words and special tokens like \"<|startoftext|>\" and \"<|endoftext|>\". The `bpe` method takes a token, checks if it's in the cache, and if not, processes it using BPE by splitting it into smaller parts until no more splits are possible.",
        "type": "comment"
    },
    "534": {
        "file_id": 12,
        "content": "                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n                    new_word.append(first + second)\n                    i += 2\n                else:\n                    new_word.append(word[i])\n                    i += 1\n            new_word = tuple(new_word)\n            word = new_word\n            if len(word) == 1:\n                break\n            else:\n                pairs = get_pairs(word)\n        word = ' '.join(word)\n        self.cache[token] = word\n        return word\n    def encode(self, text):\n        bpe_tokens = []\n        text = whitespace_clean(basic_clean(text)).lower()\n        for token in re.findall(self.pat, text):\n            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n        return bpe_tokens\n    def decode(self, tokens, remove_start_end = True, pad_tokens = set()):\n        if torch.is_tensor(tokens):\n            tokens = tokens.tolist()",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:100-126"
    },
    "535": {
        "file_id": 12,
        "content": "Code snippet is from a byte-pair encoding (BPE) tokenizer implementation in PyTorch. The code encodes input text into BPE tokens, performs wordpiece tokenization, and caches the mapping between tokens and words for decoding. The encode() function processes the input text by applying preprocessing steps, performing BPE, and extending tokens list with BPE tokens. The decode() function allows decoding of encoded tokens back to words using cached mappings.",
        "type": "comment"
    },
    "536": {
        "file_id": 12,
        "content": "        if remove_start_end:\n            tokens = [token for token in tokens if token not in (49406, 40407, 0)]\n        text = ''.join([self.decoder[token] for token in tokens if token not in pad_tokens])\n        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n        return text\n    def tokenize(self, texts, context_length = 256, truncate_text = False):\n        if isinstance(texts, str):\n            texts = [texts]\n        all_tokens = [self.encode(text) for text in texts]\n        result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n        for i, tokens in enumerate(all_tokens):\n            if len(tokens) > context_length:\n                if truncate_text:\n                    tokens = tokens[:context_length]\n                else:\n                    raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n            result[i, :len(tokens)] = torch.tensor(tokens)\n        return result\ntokenizer = SimpleTokenizer()",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:128-151"
    },
    "537": {
        "file_id": 12,
        "content": "The code defines a SimpleTokenizer class that tokenizes input texts using an encoding scheme and provides a method to convert encoded tokens into human-readable text. It also includes a tokenize function to process multiple input texts, considering context length limitations and handling truncation. The provided code snippet focuses on the process of converting encoded tokens into text.",
        "type": "comment"
    },
    "538": {
        "file_id": 12,
        "content": "# YTTM tokenizer\nclass YttmTokenizer:\n    def __init__(self, bpe_path = None):\n        bpe_path = Path(bpe_path)\n        assert bpe_path.exists(), f'BPE json path {str(bpe_path)} does not exist'\n        self.yttm = import_or_print_error('youtokentome', 'you need to install youtokentome by `pip install youtokentome`')\n        tokenizer = self.yttm.BPE(model = str(bpe_path))\n        self.tokenizer = tokenizer\n        self.vocab_size = tokenizer.vocab_size()\n    def decode(self, tokens, pad_tokens = set()):\n        if torch.is_tensor(tokens):\n            tokens = tokens.tolist()\n        return self.tokenizer.decode(tokens, ignore_ids = pad_tokens.union({0}))\n    def encode(self, texts):\n        encoded = self.tokenizer.encode(texts, output_type = self.yttm.OutputType.ID)\n        return list(map(torch.tensor, encoded))\n    def tokenize(self, texts, context_length = 256, truncate_text = False):\n        if isinstance(texts, str):\n            texts = [texts]\n        all_tokens = self.encode(texts)\n        result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:153-182"
    },
    "539": {
        "file_id": 12,
        "content": "This code defines a YTTM tokenizer class in PyTorch. The constructor loads the BPE model from the specified path and initializes the tokenizer instance, which can decode and encode text sequences. The decode function converts tokenized lists to human-readable strings, while the encode function transforms input texts into tokenized lists. The tokenize method takes a list of texts, encodes them, and returns a tensor of shape (number_of_texts, context_length) for further processing.",
        "type": "comment"
    },
    "540": {
        "file_id": 12,
        "content": "        for i, tokens in enumerate(all_tokens):\n            if len(tokens) > context_length:\n                if truncate_text:\n                    tokens = tokens[:context_length]\n                else:\n                    raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n            result[i, :len(tokens)] = torch.tensor(tokens)\n        return result",
        "type": "code",
        "location": "/dalle2_pytorch/tokenizer.py:183-191"
    },
    "541": {
        "file_id": 12,
        "content": "This code segment iterates through all tokens in a list, truncating any token sequence longer than the specified context length. If truncation is not allowed and an input text is too long, it raises a RuntimeError. The truncated or original tokens are then converted to torch tensors and stored in a result array.",
        "type": "comment"
    },
    "542": {
        "file_id": 13,
        "content": "/dalle2_pytorch/trackers.py",
        "type": "filepath"
    },
    "543": {
        "file_id": 13,
        "content": "The code initializes trackers and loggers, provides methods for logging data, saving configurations, and metadata. It saves states and models, manages loading/saving checkpoints, and handles errors with a \"recall()\" function.",
        "type": "summary"
    },
    "544": {
        "file_id": 13,
        "content": "import urllib.request\nimport os\nimport json\nfrom pathlib import Path\nimport shutil\nfrom itertools import zip_longest\nfrom typing import Any, Optional, List, Union\nfrom pydantic import BaseModel\nimport torch\nfrom dalle2_pytorch.dalle2_pytorch import Decoder, DiffusionPrior\nfrom dalle2_pytorch.utils import import_or_print_error\nfrom dalle2_pytorch.trainer import DecoderTrainer, DiffusionPriorTrainer\nfrom dalle2_pytorch.version import __version__\nfrom packaging import version\n# constants\nDEFAULT_DATA_PATH = './.tracker-data'\n# helper functions\ndef exists(val):\n    return val is not None\nclass BaseLogger:\n    \"\"\"\n    An abstract class representing an object that can log data.\n    Parameters:\n        data_path (str): A file path for storing temporary data.\n        verbose (bool): Whether of not to always print logs to the console.\n    \"\"\"\n    def __init__(self, data_path: str, resume: bool = False, auto_resume: bool = False, verbose: bool = False, **kwargs):\n        self.data_path = Path(data_path)\n        self.resume = resume",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:1-35"
    },
    "545": {
        "file_id": 13,
        "content": "This code is from the \"trackers.py\" file in the DALLE2-pytorch library, containing a class for base logger objects that can log data with optional data storage path and verbosity control. The class initializes with specified parameters like data_path, resume, auto_resume, and verbose. It uses Pathlib for path manipulation and supports temporary data storage.",
        "type": "comment"
    },
    "546": {
        "file_id": 13,
        "content": "        self.auto_resume = auto_resume\n        self.verbose = verbose\n    def init(self, full_config: BaseModel, extra_config: dict, **kwargs) -> None:\n        \"\"\"\n        Initializes the logger.\n        Errors if the logger is invalid.\n        full_config is the config file dict while extra_config is anything else from the script that is not defined the config file.\n        \"\"\"\n        raise NotImplementedError\n    def log(self, log, **kwargs) -> None:\n        raise NotImplementedError\n    def log_images(self, images, captions=[], image_section=\"images\", **kwargs) -> None:\n        raise NotImplementedError\n    def log_file(self, file_path, **kwargs) -> None:\n        raise NotImplementedError\n    def log_error(self, error_string, **kwargs) -> None:\n        raise NotImplementedError\n    def get_resume_data(self, **kwargs) -> dict:\n        \"\"\"\n        Sets tracker attributes that along with { \"resume\": True } will be used to resume training.\n        It is assumed that after init is called this data will be complete.",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:36-62"
    },
    "547": {
        "file_id": 13,
        "content": "The code defines a logger class with methods for logging different types of data, and an initialization method to set up the logger. The logger raises a NotImplementedError for each method, which means they need to be implemented in child classes. The get_resume_data method sets tracker attributes used to resume training if needed.",
        "type": "comment"
    },
    "548": {
        "file_id": 13,
        "content": "        If the logger does not have any resume functionality, it should return an empty dict.\n        \"\"\"\n        raise NotImplementedError\nclass ConsoleLogger(BaseLogger):\n    def init(self, full_config: BaseModel, extra_config: dict, **kwargs) -> None:\n        print(\"Logging to console\")\n    def log(self, log, **kwargs) -> None:\n        print(log)\n    def log_images(self, images, captions=[], image_section=\"images\", **kwargs) -> None:\n        pass\n    def log_file(self, file_path, **kwargs) -> None:\n        pass\n    def log_error(self, error_string, **kwargs) -> None:\n        print(error_string)\n    def get_resume_data(self, **kwargs) -> dict:\n        return {}\nclass WandbLogger(BaseLogger):\n    \"\"\"\n    Logs to a wandb run.\n    Parameters:\n        data_path (str): A file path for storing temporary data.\n        wandb_entity (str): The wandb entity to log to.\n        wandb_project (str): The wandb project to log to.\n        wandb_run_id (str): The wandb run id to resume.\n        wandb_run_name (str): The wandb run name to use.",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:63-94"
    },
    "549": {
        "file_id": 13,
        "content": "This code defines two logger classes, ConsoleLogger and WandbLogger, which inherit from the BaseLogger class. The ConsoleLogger logs to the console while the WandbLogger logs data to a Weights & Biases (WandB) run. Both loggers have methods for logging different types of data such as logs, images, files, and errors. The ConsoleLogger returns an empty dictionary if resuming is not supported, whereas the WandbLogger requires additional parameters like wandb_entity, wandb_project, wandb_run_id, and wandb_run_name for proper functioning.",
        "type": "comment"
    },
    "550": {
        "file_id": 13,
        "content": "    \"\"\"\n    def __init__(self,\n        data_path: str,\n        wandb_entity: str,\n        wandb_project: str,\n        wandb_run_id: Optional[str] = None,\n        wandb_run_name: Optional[str] = None,\n        **kwargs\n    ):\n        super().__init__(data_path, **kwargs)\n        self.entity = wandb_entity\n        self.project = wandb_project\n        self.run_id = wandb_run_id\n        self.run_name = wandb_run_name\n    def init(self, full_config: BaseModel, extra_config: dict, **kwargs) -> None:\n        assert self.entity is not None, \"wandb_entity must be specified for wandb logger\"\n        assert self.project is not None, \"wandb_project must be specified for wandb logger\"\n        self.wandb = import_or_print_error('wandb', '`pip install wandb` to use the wandb logger')\n        os.environ[\"WANDB_SILENT\"] = \"true\"\n        # Initializes the wandb run\n        init_object = {\n            \"entity\": self.entity,\n            \"project\": self.project,\n            \"config\": {**full_config.dict(), **extra_config}\n        }",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:95-120"
    },
    "551": {
        "file_id": 13,
        "content": "This code is a Python class for creating and initializing a WandB logger. It requires a data path, WandB entity, and project parameters. The class also supports additional configuration options. If the WandB entity or project are not specified, an error will be raised.",
        "type": "comment"
    },
    "552": {
        "file_id": 13,
        "content": "        if self.run_name is not None:\n            init_object['name'] = self.run_name\n        if self.resume:\n            assert self.run_id is not None, '`wandb_run_id` must be provided if `wandb_resume` is True'\n            if self.run_name is not None:\n                print(\"You are renaming a run. I hope that is what you intended.\")\n            init_object['resume'] = 'must'\n            init_object['id'] = self.run_id\n        self.wandb.init(**init_object)\n        print(f\"Logging to wandb run {self.wandb.run.path}-{self.wandb.run.name}\")\n    def log(self, log, **kwargs) -> None:\n        if self.verbose:\n            print(log)\n        self.wandb.log(log, **kwargs)\n    def log_images(self, images, captions=[], image_section=\"images\", **kwargs) -> None:\n        \"\"\"\n        Takes a tensor of images and a list of captions and logs them to wandb.\n        \"\"\"\n        wandb_images = [self.wandb.Image(image, caption=caption) for image, caption in zip_longest(images, captions)]\n        self.wandb.log({ image_section: wandb_images }, **kwargs)",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:121-143"
    },
    "553": {
        "file_id": 13,
        "content": "This code initializes a Wandb tracker, allowing for easy logging of data to a specific run. If `run_id` is provided and `wandb_resume` is True, the run is resumed with a warning about renaming. The code then logs various types of data including logs, images with captions, using the Wandb API. Verbose output is also supported for logs.",
        "type": "comment"
    },
    "554": {
        "file_id": 13,
        "content": "    def log_file(self, file_path, base_path: Optional[str] = None, **kwargs) -> None:\n        if base_path is None:\n            # Then we take the basepath as the parent of the file_path\n            base_path = Path(file_path).parent\n        self.wandb.save(str(file_path), base_path = str(base_path))\n    def log_error(self, error_string, step=None, **kwargs) -> None:\n        if self.verbose:\n            print(error_string)\n        self.wandb.log({\"error\": error_string, **kwargs}, step=step)\n    def get_resume_data(self, **kwargs) -> dict:\n        # In order to resume, we need wandb_entity, wandb_project, and wandb_run_id\n        return {\n            \"entity\": self.entity,\n            \"project\": self.project,\n            \"run_id\": self.wandb.run.id\n        }\nlogger_type_map = {\n    'console': ConsoleLogger,\n    'wandb': WandbLogger,\n}\ndef create_logger(logger_type: str, data_path: str, **kwargs) -> BaseLogger:\n    if logger_type == 'custom':\n        raise NotImplementedError('Custom loggers are not supported yet. Please use a different logger type.')",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:145-170"
    },
    "555": {
        "file_id": 13,
        "content": "The code defines a class with three methods: `log_file`, `log_error`, and `get_resume_data`. The `log_file` method logs a file path, `log_error` logs an error string, and `get_resume_data` returns a dictionary containing essential resume information. Additionally, there is a function `create_logger` which creates a logger of type 'console' or 'wandb'. For now, custom loggers are not supported.",
        "type": "comment"
    },
    "556": {
        "file_id": 13,
        "content": "    try:\n        logger_class = logger_type_map[logger_type]\n    except KeyError:\n        raise ValueError(f'Unknown logger type: {logger_type}. Must be one of {list(logger_type_map.keys())}')\n    return logger_class(data_path, **kwargs)\nclass BaseLoader:\n    \"\"\"\n    An abstract class representing an object that can load a model checkpoint.\n    Parameters:\n        data_path (str): A file path for storing temporary data.\n    \"\"\"\n    def __init__(self, data_path: str, only_auto_resume: bool = False, **kwargs):\n        self.data_path = Path(data_path)\n        self.only_auto_resume = only_auto_resume\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        raise NotImplementedError\n    def recall() -> dict:\n        raise NotImplementedError\nclass UrlLoader(BaseLoader):\n    \"\"\"\n    A loader that downloads the file from a url and loads it\n    Parameters:\n        data_path (str): A file path for storing temporary data.\n        url (str): The url to download the file from.\n    \"\"\"\n    def __init__(self, data_path: str, url: str, **kwargs):",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:171-200"
    },
    "557": {
        "file_id": 13,
        "content": "Function tries to create an instance of a logger class based on the given type, otherwise it raises a ValueError. BaseLoader is an abstract class that can be used to load model checkpoints with data_path and optionally other parameters. UrlLoader extends BaseLoader by allowing loading files from URLs instead of local file paths.",
        "type": "comment"
    },
    "558": {
        "file_id": 13,
        "content": "        super().__init__(data_path, **kwargs)\n        self.url = url\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        # Makes sure the file exists to be downloaded\n        pass  # TODO: Actually implement that\n    def recall(self) -> dict:\n        # Download the file\n        save_path = self.data_path / 'loaded_checkpoint.pth'\n        urllib.request.urlretrieve(self.url, str(save_path))\n        # Load the file\n        return torch.load(str(save_path), map_location='cpu')\nclass LocalLoader(BaseLoader):\n    \"\"\"\n    A loader that loads a file from a local path\n    Parameters:\n        data_path (str): A file path for storing temporary data.\n        file_path (str): The path to the file to load.\n    \"\"\"\n    def __init__(self, data_path: str, file_path: str, **kwargs):\n        super().__init__(data_path, **kwargs)\n        self.file_path = Path(file_path)\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        # Makes sure the file exists to be loaded\n        if not self.file_path.exists() and not self.only_auto_resume:",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:201-229"
    },
    "559": {
        "file_id": 13,
        "content": "The code defines a base class, \"BaseLoader\", which is responsible for loading files from a given data path. It initializes the class by setting the URL and has an init method to check if the file exists. The \"recall\" method downloads the file and loads it into memory. Additionally, there is a subclass called \"LocalLoader\" that loads files from local paths, checking if the file exists before loading it.",
        "type": "comment"
    },
    "560": {
        "file_id": 13,
        "content": "            raise FileNotFoundError(f'Model not found at {self.file_path}')\n    def recall(self) -> dict:\n        # Load the file\n        return torch.load(str(self.file_path), map_location='cpu')\nclass WandbLoader(BaseLoader):\n    \"\"\"\n    A loader that loads a model from an existing wandb run\n    \"\"\"\n    def __init__(self, data_path: str, wandb_file_path: str, wandb_run_path: Optional[str] = None, **kwargs):\n        super().__init__(data_path, **kwargs)\n        self.run_path = wandb_run_path\n        self.file_path = wandb_file_path\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        self.wandb = import_or_print_error('wandb', '`pip install wandb` to use the wandb recall function')\n        # Make sure the file can be downloaded\n        if self.wandb.run is not None and self.run_path is None:\n            self.run_path = self.wandb.run.path\n            assert self.run_path is not None, 'wandb run was not found to load from. If not using the wandb logger must specify the `wandb_run_path`.'\n        assert self.run_path is not None, '`wandb_run_path` must be provided for the wandb loader'",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:230-251"
    },
    "561": {
        "file_id": 13,
        "content": "This code defines a class `WandbLoader` that loads a model from an existing W&B (Weights & Biases) run. It requires a data path, a file path within the W&B run, and optionally a W&B run path. The `__init__` method initializes the object, the `init` method ensures the file can be downloaded, and the `recall` method loads the model using `torch.load`. If a W&B run is available but the run path is not specified, it sets the run path to the current run's path. The code also imports the 'wandb' library if it is missing.",
        "type": "comment"
    },
    "562": {
        "file_id": 13,
        "content": "        assert self.file_path is not None, '`wandb_file_path` must be provided for the wandb loader'\n        os.environ[\"WANDB_SILENT\"] = \"true\"\n        pass  # TODO: Actually implement that\n    def recall(self) -> dict:\n        file_reference = self.wandb.restore(self.file_path, run_path=self.run_path)\n        return torch.load(file_reference.name, map_location='cpu')\nloader_type_map = {\n    'url': UrlLoader,\n    'local': LocalLoader,\n    'wandb': WandbLoader,\n}\ndef create_loader(loader_type: str, data_path: str, **kwargs) -> BaseLoader:\n    if loader_type == 'custom':\n        raise NotImplementedError('Custom loaders are not supported yet. Please use a different loader type.')\n    try:\n        loader_class = loader_type_map[loader_type]\n    except KeyError:\n        raise ValueError(f'Unknown loader type: {loader_type}. Must be one of {list(loader_type_map.keys())}')\n    return loader_class(data_path, **kwargs)\nclass BaseSaver:\n    def __init__(self,\n        data_path: str,\n        save_latest_to: Optional[Union[str, bool]] = None,",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:252-278"
    },
    "563": {
        "file_id": 13,
        "content": "This code defines a `BaseSaver` class with an optional parameter for saving the latest data to a specified location. It also includes a function `create_loader()` that creates different types of loaders (url, local, wandb) based on the provided loader type and data path. The WandbLoader is used to restore data from a specified file path using Weights & Biases environment.",
        "type": "comment"
    },
    "564": {
        "file_id": 13,
        "content": "        save_best_to: Optional[Union[str, bool]] = None,\n        save_meta_to: Optional[str] = None,\n        save_type: str = 'checkpoint',\n        **kwargs\n    ):\n        self.data_path = Path(data_path)\n        self.save_latest_to = save_latest_to\n        self.saving_latest = save_latest_to is not None and save_latest_to is not False\n        self.save_best_to = save_best_to\n        self.saving_best = save_best_to is not None and save_best_to is not False\n        self.save_meta_to = save_meta_to\n        self.saving_meta = save_meta_to is not None\n        self.save_type = save_type\n        assert save_type in ['checkpoint', 'model'], '`save_type` must be one of `checkpoint` or `model`'\n        assert self.saving_latest or self.saving_best or self.saving_meta, 'At least one saving option must be specified'\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        raise NotImplementedError\n    def save_file(self, local_path: Path, save_path: str, is_best=False, is_latest=False, **kwargs) -> None:\n        \"\"\"",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:279-299"
    },
    "565": {
        "file_id": 13,
        "content": "This code defines a tracker class that handles saving of data to specified locations. It allows saving the latest, best, and meta information, with options for file type and paths. The `save_file` method is used to save files with optional flags for best and latest status. An assertion ensures that the save type is either 'checkpoint' or 'model'. A final assertion requires at least one saving option to be specified.",
        "type": "comment"
    },
    "566": {
        "file_id": 13,
        "content": "        Save a general file under save_meta_to\n        \"\"\"\n        raise NotImplementedError\nclass LocalSaver(BaseSaver):\n    def __init__(self,\n        data_path: str,\n        **kwargs\n    ):\n        super().__init__(data_path, **kwargs)\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        # Makes sure the directory exists to be saved to\n        print(f\"Saving {self.save_type} locally\")\n        if not self.data_path.exists():\n            self.data_path.mkdir(parents=True)\n    def save_file(self, local_path: str, save_path: str, **kwargs) -> None:\n        # Copy the file to save_path\n        save_path_file_name = Path(save_path).name\n        # Make sure parent directory exists\n        save_path_parent = Path(save_path).parent\n        if not save_path_parent.exists():\n            save_path_parent.mkdir(parents=True)\n        print(f\"Saving {save_path_file_name} {self.save_type} to local path {save_path}\")\n        shutil.copy(local_path, save_path)\nclass WandbSaver(BaseSaver):\n    def __init__(self, data_path: str, wandb_run_path: Optional[str] = None, **kwargs):",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:300-328"
    },
    "567": {
        "file_id": 13,
        "content": "This code defines two classes, LocalSaver and WandbSaver, which inherit from BaseSaver. Both classes are responsible for saving files in different locations. The LocalSaver saves files locally to a specified data_path, ensuring the directory exists beforehand. The WandbSaver is optional and requires a wandb_run_path parameter.",
        "type": "comment"
    },
    "568": {
        "file_id": 13,
        "content": "        super().__init__(data_path, **kwargs)\n        self.run_path = wandb_run_path\n    def init(self, logger: BaseLogger, **kwargs) -> None:\n        self.wandb = import_or_print_error('wandb', '`pip install wandb` to use the wandb logger')\n        os.environ[\"WANDB_SILENT\"] = \"true\"\n        # Makes sure that the user can upload tot his run\n        if self.run_path is not None:\n            entity, project, run_id = self.run_path.split(\"/\")\n            self.run = self.wandb.init(entity=entity, project=project, id=run_id)\n        else:\n            assert self.wandb.run is not None, 'You must be using the wandb logger if you are saving to wandb and have not set `wandb_run_path`'\n            self.run = self.wandb.run\n        # TODO: Now actually check if upload is possible\n        print(f\"Saving to wandb run {self.run.path}-{self.run.name}\")\n    def save_file(self, local_path: Path, save_path: str, **kwargs) -> None:\n        # In order to log something in the correct place in wandb, we need to have the same file structure here",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:329-346"
    },
    "569": {
        "file_id": 13,
        "content": "This code initializes a W&B run based on the `wandb_run_path` provided. It imports the W&B library, sets up the environment for uploading to W&B runs, and checks if the user has access to save files in the specified W&B run path.",
        "type": "comment"
    },
    "570": {
        "file_id": 13,
        "content": "        save_path_file_name = Path(save_path).name\n        print(f\"Saving {save_path_file_name} {self.save_type} to wandb run {self.run.path}-{self.run.name}\")\n        save_path = Path(self.data_path) / save_path\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        shutil.copy(local_path, save_path)\n        self.run.save(str(save_path), base_path = str(self.data_path), policy='now')\nclass HuggingfaceSaver(BaseSaver):\n    def __init__(self, data_path: str, huggingface_repo: str, token_path: Optional[str] = None, **kwargs):\n        super().__init__(data_path, **kwargs)\n        self.huggingface_repo = huggingface_repo\n        self.token_path = token_path\n    def init(self, logger: BaseLogger, **kwargs):\n        # Makes sure this user can upload to the repo\n        self.hub = import_or_print_error('huggingface_hub', '`pip install huggingface_hub` to use the huggingface saver')\n        try:\n            identity = self.hub.whoami()  # Errors if not logged in\n            # Then we are logged in",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:347-365"
    },
    "571": {
        "file_id": 13,
        "content": "This code defines a `HuggingfaceSaver` class that saves files to a Hugging Face repository. It initializes the instance with a data path, Hugging Face repo, and optional token path. The `init` method checks if the user is logged in to the Hugging Face hub and then saves the file specified by `save_path` using `self.hub.upload`.",
        "type": "comment"
    },
    "572": {
        "file_id": 13,
        "content": "        except:\n            # We are not logged in. Use the token_path to set the token.\n            if not os.path.exists(self.token_path):\n                raise Exception(\"Not logged in to huggingface and no token_path specified. Please login with `huggingface-cli login` or if that does not work set the token_path.\")\n            with open(self.token_path, \"r\") as f:\n                token = f.read().strip()\n            self.hub.HfApi.set_access_token(token)\n            identity = self.hub.whoami()\n        print(f\"Saving to huggingface repo {self.huggingface_repo}\")\n    def save_file(self, local_path: Path, save_path: str, **kwargs) -> None:\n        # Saving to huggingface is easy, we just need to upload the file with the correct name\n        save_path_file_name = Path(save_path).name\n        print(f\"Saving {save_path_file_name} {self.save_type} to huggingface repo {self.huggingface_repo}\")\n        self.hub.upload_file(\n            path_or_fileobj=str(local_path),\n            path_in_repo=str(save_path),",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:366-382"
    },
    "573": {
        "file_id": 13,
        "content": "This code handles saving a file to the HuggingFace repo. If not logged in, it checks for a token path and uses it if available, or throws an exception. It then prints the saving path, logs in with the token (if provided), and finally uploads the file to the specified HuggingFace repo.",
        "type": "comment"
    },
    "574": {
        "file_id": 13,
        "content": "            repo_id=self.huggingface_repo\n        )\nsaver_type_map = {\n    'local': LocalSaver,\n    'wandb': WandbSaver,\n    'huggingface': HuggingfaceSaver\n}\ndef create_saver(saver_type: str, data_path: str, **kwargs) -> BaseSaver:\n    if saver_type == 'custom':\n        raise NotImplementedError('Custom savers are not supported yet. Please use a different saver type.')\n    try:\n        saver_class = saver_type_map[saver_type]\n    except KeyError:\n        raise ValueError(f'Unknown saver type: {saver_type}. Must be one of {list(saver_type_map.keys())}')\n    return saver_class(data_path, **kwargs)\nclass Tracker:\n    def __init__(self, data_path: Optional[str] = DEFAULT_DATA_PATH, overwrite_data_path: bool = False, dummy_mode: bool = False):\n        self.data_path = Path(data_path)\n        if not dummy_mode:\n            if not overwrite_data_path:\n                assert not self.data_path.exists(), f'Data path {self.data_path} already exists. Set overwrite_data_path to True to overwrite.'\n                if not self.data_path.exists():",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:383-407"
    },
    "575": {
        "file_id": 13,
        "content": "Function create_saver takes a saver type and data path, returns a BaseSaver object. It supports 'local', 'wandb', and 'huggingface' saver types. If the saver type is 'custom', it raises an error since custom savers aren't supported yet. Tracker initializes with optional data_path, overwrite_data_path (to overwrite existing path), and dummy_mode (if running in simulation mode). If not in dummy mode, asserts that the data path doesn't exist unless overwrite_data_path is True.",
        "type": "comment"
    },
    "576": {
        "file_id": 13,
        "content": "                    self.data_path.mkdir(parents=True)\n        self.logger: BaseLogger = None\n        self.loader: Optional[BaseLoader] = None\n        self.savers: List[BaseSaver]= []\n        self.dummy_mode = dummy_mode\n    def _load_auto_resume(self) -> bool:\n        # If the file does not exist, we return False. If autoresume is enabled we print a warning so that the user can know that this is the first run.\n        if not self.auto_resume_path.exists():\n            if self.logger.auto_resume:\n                print(\"Auto_resume is enabled but no auto_resume.json file exists. Assuming this is the first run.\")\n            return False\n        # Now we know that the autoresume file exists, but if we are not auto resuming we should remove it so that we don't accidentally load it next time\n        if not self.logger.auto_resume:\n            print(f'Removing auto_resume.json because auto_resume is not enabled in the config')\n            self.auto_resume_path.unlink()\n            return False\n        # Otherwise we read the json into a dictionary will will override parts of logger.__dict__",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:408-427"
    },
    "577": {
        "file_id": 13,
        "content": "This code initializes a tracker object, handling the data path creation, base logger and loader setup, saving list initialization, and dummy mode. It also includes a method to load auto-resume configuration if it exists, printing warnings for first run or removing the file if auto-resume is not enabled.",
        "type": "comment"
    },
    "578": {
        "file_id": 13,
        "content": "        with open(self.auto_resume_path, 'r') as f:\n            auto_resume_dict = json.load(f)\n        # Check if the logger is of the same type as the autoresume save\n        if auto_resume_dict[\"logger_type\"] != self.logger.__class__.__name__:\n            raise Exception(f'The logger type in the auto_resume file is {auto_resume_dict[\"logger_type\"]} but the current logger is {self.logger.__class__.__name__}. Either use the original logger type, set `auto_resume` to `False`, or delete your existing tracker-data folder.')\n        # Then we are ready to override the logger with the autoresume save\n        self.logger.__dict__[\"resume\"] = True\n        print(f\"Updating {self.logger.__dict__} with {auto_resume_dict}\")\n        self.logger.__dict__.update(auto_resume_dict)\n        return True\n    def _save_auto_resume(self):\n        # Gets the autoresume dict from the logger and adds \"logger_type\" to it then saves it to the auto_resume file\n        auto_resume_dict = self.logger.get_resume_data()\n        auto_resume_dict['logger_type'] = self.logger.__class__.__name__",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:428-442"
    },
    "579": {
        "file_id": 13,
        "content": "This code reads a previously saved state from the \"auto_resume_path\" and checks if the logger type matches the current logger. If they don't match, it raises an exception with instructions on how to proceed. Otherwise, it updates the logger with the auto-resume data and returns True.",
        "type": "comment"
    },
    "580": {
        "file_id": 13,
        "content": "        with open(self.auto_resume_path, 'w') as f:\n            json.dump(auto_resume_dict, f)\n    def init(self, full_config: BaseModel, extra_config: dict):\n        self.auto_resume_path = self.data_path / 'auto_resume.json'\n        # Check for resuming the run\n        self.did_auto_resume = self._load_auto_resume()\n        if self.did_auto_resume:\n            print(f'\\n\\nWARNING: RUN HAS BEEN AUTO-RESUMED WITH THE LOGGER TYPE {self.logger.__class__.__name__}.\\nIf this was not your intention, stop this run and set `auto_resume` to `False` in the config.\\n\\n')\n            print(f\"New logger config: {self.logger.__dict__}\")\n        self.save_metadata = dict(\n            version = version.parse(__version__)\n        )  # Data that will be saved alongside the checkpoint or model\n        self.blacklisted_checkpoint_metadata_keys = ['scaler', 'optimizer', 'model', 'version', 'step', 'steps']  # These keys would cause us to error if we try to save them as metadata\n        assert self.logger is not None, '`logger` must be set before `init` is called'",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:443-459"
    },
    "581": {
        "file_id": 13,
        "content": "This code is initializing a tracker object. It sets the auto_resume path, checks for resuming the run and prints a warning if it was automatically resumed. The save_metadata dictionary is created with version information and some keys are blacklisted from being saved as metadata to avoid errors during saving. The logger must be set before calling init method.",
        "type": "comment"
    },
    "582": {
        "file_id": 13,
        "content": "        if self.dummy_mode:\n            # The only thing we need is a loader\n            if self.loader is not None:\n                self.loader.init(self.logger)\n            return\n        assert len(self.savers) > 0, '`savers` must be set before `init` is called'\n        self.logger.init(full_config, extra_config)\n        if self.loader is not None:\n            self.loader.init(self.logger)\n        for saver in self.savers:\n            saver.init(self.logger)\n        if self.logger.auto_resume:\n            # Then we need to save the autoresume file. It is assumed after logger.init is called that the logger is ready to be saved.\n            self._save_auto_resume()\n    def add_logger(self, logger: BaseLogger):\n        self.logger = logger\n    def add_loader(self, loader: BaseLoader):\n        self.loader = loader\n    def add_saver(self, saver: BaseSaver):\n        self.savers.append(saver)\n    def log(self, *args, **kwargs):\n        if self.dummy_mode:\n            return\n        self.logger.log(*args, **kwargs)",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:460-489"
    },
    "583": {
        "file_id": 13,
        "content": "This code initializes trackers by first checking if in dummy mode, then initializing loaders and savers. The logger is initialized only if the `savers` list has items, and if `auto_resume` is enabled, it saves an autoresume file. The `add_logger`, `add_loader`, `add_saver`, and `log` methods are provided to interact with trackers' components.",
        "type": "comment"
    },
    "584": {
        "file_id": 13,
        "content": "    def log_images(self, *args, **kwargs):\n        if self.dummy_mode:\n            return\n        self.logger.log_images(*args, **kwargs)\n    def log_file(self, *args, **kwargs):\n        if self.dummy_mode:\n            return\n        self.logger.log_file(*args, **kwargs)\n    def save_config(self, current_config_path: str, config_name = 'config.json'):\n        if self.dummy_mode:\n            return\n        # Save the config under config_name in the root folder of data_path\n        shutil.copy(current_config_path, self.data_path / config_name)\n        for saver in self.savers:\n            if saver.saving_meta:\n                remote_path = Path(saver.save_meta_to) / config_name\n                saver.save_file(current_config_path, str(remote_path))\n    def add_save_metadata(self, state_dict_key: str, metadata: Any):\n        \"\"\"\n        Adds a new piece of metadata that will be saved along with the model or decoder.\n        \"\"\"\n        self.save_metadata[state_dict_key] = metadata\n    def _save_state_dict(self,",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:491-517"
    },
    "585": {
        "file_id": 13,
        "content": "This code is from the DALLE2-pytorch library and it contains several methods for logging images, files, saving configurations, and adding save metadata. The dummy_mode check prevents unnecessary actions when in a test mode. The save_config method copies the current config file to the root folder of the data_path and saves it remotely if specified by the saver. The add_save_metadata method adds new metadata that will be saved along with the model or decoder.",
        "type": "comment"
    },
    "586": {
        "file_id": 13,
        "content": " trainer: Union[DiffusionPriorTrainer, DecoderTrainer], save_type: str, file_path: str, **kwargs) -> Path:\n        \"\"\"\n        Gets the state dict to be saved and writes it to file_path.\n        If save_type is 'checkpoint', we save the entire trainer state dict.\n        If save_type is 'model', we save only the model state dict.\n        \"\"\"\n        assert save_type in ['checkpoint', 'model']\n        if save_type == 'checkpoint':\n            # Create a metadata dict without the blacklisted keys so we do not error when we create the state dict\n            metadata = {k: v for k, v in self.save_metadata.items() if k not in self.blacklisted_checkpoint_metadata_keys}\n            trainer.save(file_path, overwrite=True, **kwargs, **metadata)\n        elif save_type == 'model':\n            if isinstance(trainer, DiffusionPriorTrainer):\n                prior = trainer.ema_diffusion_prior.ema_model if trainer.use_ema else trainer.diffusion_prior\n                prior: DiffusionPrior = trainer.accelerator.unwrap_model(prior)",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:517-531"
    },
    "587": {
        "file_id": 13,
        "content": "This function saves the trainer's state dict, depending on the 'save_type' parameter. If 'checkpoint', it saves the entire trainer state without blacklisted metadata keys. If 'model', it saves only the model state if the trainer is a DiffusionPriorTrainer.",
        "type": "comment"
    },
    "588": {
        "file_id": 13,
        "content": "                # Remove CLIP if it is part of the model\n                original_clip = prior.clip\n                prior.clip = None\n                model_state_dict = prior.state_dict()\n                prior.clip = original_clip\n            elif isinstance(trainer, DecoderTrainer):\n                decoder: Decoder = trainer.accelerator.unwrap_model(trainer.decoder)\n                # Remove CLIP if it is part of the model\n                original_clip = decoder.clip\n                decoder.clip = None\n                if trainer.use_ema:\n                    trainable_unets = decoder.unets\n                    decoder.unets = trainer.unets  # Swap EMA unets in\n                    model_state_dict = decoder.state_dict()\n                    decoder.unets = trainable_unets  # Swap back\n                else:\n                    model_state_dict = decoder.state_dict()\n                decoder.clip = original_clip\n            else:\n                raise NotImplementedError('Saving this type of model with EMA mode enabled is not yet implemented. Actually, how did you get here?')",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:532-551"
    },
    "589": {
        "file_id": 13,
        "content": "This code checks the type of trainer and removes CLIP from the model if it is part of it. It then saves the state dictionary for the model, and optionally swaps EMA unets in or out depending on the use_ema flag. Finally, it restores the original CLIP state.",
        "type": "comment"
    },
    "590": {
        "file_id": 13,
        "content": "            state_dict = {\n                **self.save_metadata,\n                'model': model_state_dict\n            }\n            torch.save(state_dict, file_path)\n        return Path(file_path)\n    def save(self, trainer, is_best: bool, is_latest: bool, **kwargs):\n        if self.dummy_mode:\n            return\n        if not is_best and not is_latest:\n            # Nothing to do\n            return\n        # Save the checkpoint and model to data_path\n        checkpoint_path = self.data_path / 'checkpoint.pth'\n        self._save_state_dict(trainer, 'checkpoint', checkpoint_path, **kwargs)\n        model_path = self.data_path / 'model.pth'\n        self._save_state_dict(trainer, 'model', model_path, **kwargs)\n        print(\"Saved cached models\")\n        # Call the save methods on the savers\n        for saver in self.savers:\n            local_path = checkpoint_path if saver.save_type == 'checkpoint' else model_path\n            if saver.saving_latest and is_latest:\n                latest_checkpoint_path = saver.save_latest_to.format(**kwargs)",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:552-575"
    },
    "591": {
        "file_id": 13,
        "content": "This code saves the model and checkpoint to specified file paths. If not in dummy mode, it checks if the 'is_best' or 'is_latest' flag is set before proceeding with saving the state dictionary for 'checkpoint' and 'model'. It then prints a message confirming the saved cached models. Lastly, it calls save methods on savers, considering the 'saving_latest' flag and appropriate file paths.",
        "type": "comment"
    },
    "592": {
        "file_id": 13,
        "content": "                try:\n                    saver.save_file(local_path, latest_checkpoint_path, is_latest=True, **kwargs)\n                except Exception as e:\n                    self.logger.log_error(f'Error saving checkpoint: {e}', **kwargs)\n                    print(f'Error saving checkpoint: {e}')\n            if saver.saving_best and is_best:\n                best_checkpoint_path = saver.save_best_to.format(**kwargs)\n                try:\n                    saver.save_file(local_path, best_checkpoint_path, is_best=True, **kwargs)\n                except Exception as e:\n                    self.logger.log_error(f'Error saving checkpoint: {e}', **kwargs)\n                    print(f'Error saving checkpoint: {e}')\n    @property\n    def can_recall(self):\n        # Defines whether a recall can be performed.\n        return self.loader is not None and (not self.loader.only_auto_resume or self.did_auto_resume)\n    def recall(self):\n        if self.can_recall:\n            return self.loader.recall()\n        else:\n",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:576-598"
    },
    "593": {
        "file_id": 13,
        "content": "This code appears to be part of a class that manages loading and saving checkpoints for a model. It has a property called \"can_recall\" which determines if a recall (loading a previously saved checkpoint) can be performed based on whether the loader is not None and certain conditions about the loader's properties. If a recall is possible, the \"recall()\" function is called to perform the actual recall. Any errors that occur during saving are logged and printed.",
        "type": "comment"
    },
    "594": {
        "file_id": 13,
        "content": "            raise ValueError('Tried to recall, but no loader was set or auto-resume was not performed.')",
        "type": "code",
        "location": "/dalle2_pytorch/trackers.py:598-598"
    },
    "595": {
        "file_id": 13,
        "content": "Raises an error when no loader is set and auto-resume was not performed.",
        "type": "comment"
    },
    "596": {
        "file_id": 14,
        "content": "/dalle2_pytorch/train_configs.py",
        "type": "filepath"
    },
    "597": {
        "file_id": 14,
        "content": "The code sets up DALL-E 2 PyTorch training configurations, provides utility functions and tracker configuration, defines a class for model training/evaluation, and suggests potential efficiency improvements.",
        "type": "summary"
    },
    "598": {
        "file_id": 14,
        "content": "import json\nfrom torchvision import transforms as T\nfrom pydantic import BaseModel, validator, model_validator\nfrom typing import List, Optional, Union, Tuple, Dict, Any, TypeVar\nfrom x_clip import CLIP as XCLIP\nfrom open_clip import list_pretrained\nfrom coca_pytorch import CoCa\nfrom dalle2_pytorch.dalle2_pytorch import (\n    CoCaAdapter,\n    OpenAIClipAdapter,\n    OpenClipAdapter,\n    Unet,\n    Decoder,\n    DiffusionPrior,\n    DiffusionPriorNetwork,\n    XClipAdapter\n)\nfrom dalle2_pytorch.trackers import Tracker, create_loader, create_logger, create_saver\n# helper functions\ndef exists(val):\n    return val is not None\ndef default(val, d):\n    return val if exists(val) else d\nInnerType = TypeVar('InnerType')\nListOrTuple = Union[List[InnerType], Tuple[InnerType]]\nSingularOrIterable = Union[InnerType, ListOrTuple[InnerType]]\n# general pydantic classes\nclass TrainSplitConfig(BaseModel):\n    train: float = 0.75\n    val: float = 0.15\n    test: float = 0.1\n    @model_validator(mode = 'after')\n    def validate_all(self, m):\n        actual_sum = sum([*dict(self).values()])",
        "type": "code",
        "location": "/dalle2_pytorch/train_configs.py:1-43"
    },
    "599": {
        "file_id": 14,
        "content": "This code is defining various classes and functions for training configurations in a machine learning application, specifically related to the DALL-E 2 PyTorch model. It includes importing necessary modules, setting up pydantic models for train splits, and creating utility functions like `default` and `exists`.",
        "type": "comment"
    }
}