{
    "800": {
        "file_id": 23,
        "content": "        \"\"\"\n        self.start = start\n    def get_start(self):\n        return self.start\n    def get_sample(self):\n        \"\"\"\n        pre-proocess data from either reader into a common format\n        \"\"\"\n        if self.text_conditioned:\n            image_embedding, caption = next(self.loader)\n            image_embedding = from_numpy(image_embedding)\n            tokenized_caption = tokenize(caption[\"caption\"].to_list(), truncate=True)\n            return image_embedding, tokenized_caption\n        else:\n            (image_embedding, _), (text_embedding, _) = next(self.loader)\n            image_embedding = from_numpy(image_embedding)\n            text_embedding = from_numpy(text_embedding)\n            return image_embedding, text_embedding\n# helper functions\ndef distribute_to_rank(start, stop, rank, world_size):\n    \"\"\"\n    Distribute data to each rank given the world size.\n    Return:\n        - New start and stop points for this rank.\n    \"\"\"\n    num_samples = int(stop - start)\n    per_rank = int(ceil((num_samples) / float(world_size)))",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:73-112"
    },
    "801": {
        "file_id": 23,
        "content": "This code defines a class with methods to manage data loading and distribution for the DALL-E 2 model. It supports text-conditioned or unconditioned data, preprocesses input into a common format, and distributes data across multiple ranks using MPI.",
        "type": "comment"
    },
    "802": {
        "file_id": 23,
        "content": "    assert (\n        per_rank > 0\n    ), f\"Number of samples per rank must be larger than 0, (found: {per_rank})\"\n    rank_start = start + rank * per_rank\n    rank_stop = min(rank_start + per_rank, stop)\n    new_length = rank_stop - rank_start\n    assert (\n        new_length > 0\n    ), \"Calculated start and stop points result in a length of zero for this rank.\"\n    return rank_start, rank_stop\ndef get_reader(\n    text_conditioned: bool, img_url: str, meta_url: str = None, txt_url: str = None\n):\n    \"\"\"\n    Create an EmbeddingReader object from the specified URLs\n    get_reader() will always expect a url to image embeddings.\n    If text-conditioned, it will also expect a meta_url for the captions.\n    Otherwise, it will need txt_url for the matching text embeddings.\n    Returns an image_reader object if text-conditioned.\n    Otherwise it returns both an image_reader and a text_reader\n    \"\"\"\n    assert img_url is not None, \"Must supply a image url\"\n    if text_conditioned:\n        assert meta_url is not None, \"Must supply meta url if text-conditioned\"",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:114-149"
    },
    "803": {
        "file_id": 23,
        "content": "The code is defining functions that calculate the start and stop points for a given rank, and another function to create an EmbeddingReader object based on URLs. It asserts that certain inputs are not None before proceeding, ensuring necessary information is provided.",
        "type": "comment"
    },
    "804": {
        "file_id": 23,
        "content": "        image_reader = EmbeddingReader(\n            embeddings_folder=img_url,\n            file_format=\"parquet_npy\",\n            # will assume the caption column exists and is the only one requested\n            meta_columns=[\"caption\"],\n            metadata_folder=meta_url,\n        )\n        return image_reader\n    # otherwise we will require text embeddings as well and return two readers\n    assert (\n        txt_url is not None\n    ), \"Must supply text embedding url if not text-conditioning\"\n    image_reader = EmbeddingReader(img_url, file_format=\"npy\")\n    text_reader = EmbeddingReader(txt_url, file_format=\"npy\")\n    return image_reader, text_reader\ndef make_splits(\n    text_conditioned: bool,\n    batch_size: int,\n    num_data_points: int,\n    train_split: float,\n    eval_split: float,\n    image_reader: EmbeddingReader,\n    text_reader: EmbeddingReader = None,\n    start=0,\n    rank=0,\n    world_size=1,\n):\n    \"\"\"\n    Split an embedding reader object as needed.\n    NOTE: make_splits() will infer the test set size from your train and eval.",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:151-187"
    },
    "805": {
        "file_id": 23,
        "content": "This code defines a function to split an embedding reader object into training, evaluation, and optional test sets. It takes in the text conditioned flag, batch size, number of data points, and train/eval splits as input parameters. If text-conditioning is not enabled, it requires text embedding URLs as well and returns two readers.",
        "type": "comment"
    },
    "806": {
        "file_id": 23,
        "content": "    Input:\n        - text_conditioned: whether to prepare text-conditioned training data\n        - batch_size: the batch size for a single gpu\n        - num_data_points: the total number of data points you wish to train on\n        - train_split: the percentage of data you wish to train on\n        - eval_split: the percentage of data you wish to validate on\n        - image_reader: the image_reader you wish to split\n        - text_reader: the text_reader you want to split (if !text_conditioned)\n        - start: the starting point within your dataset\n        - rank: the rank of your worker\n        - world_size: the total world size of your distributed training run\n    Returns:\n        - PyTorch Dataloaders that yield tuples of (img, txt) data.\n    \"\"\"\n    assert start < image_reader.count, \"start position cannot exceed reader count.\"\n    # verify that the num_data_points does not exceed the max points\n    if num_data_points > (image_reader.count - start):\n        print(\n            \"Specified count is larger than what's available...defaulting to reader's count.\"",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:189-210"
    },
    "807": {
        "file_id": 23,
        "content": "This function takes various inputs like batch size, train and eval splits, readers, and starting point to create PyTorch Dataloaders for image-text pairs. It ensures the start position is within the reader's count, and if the specified data points count exceeds the available ones, it defaults to the remaining count.",
        "type": "comment"
    },
    "808": {
        "file_id": 23,
        "content": "        )\n        num_data_points = image_reader.count\n    # compute split points\n    train_set_size = int(train_split * num_data_points)\n    eval_set_size = int(eval_split * num_data_points)\n    eval_start = train_set_size\n    eval_stop = int(eval_start + eval_set_size)\n    assert (\n        train_split + eval_split\n    ) < 1.0, \"Specified train and eval split is too large to infer a test split.\"\n    # distribute to rank\n    rank_train_start, rank_train_stop = distribute_to_rank(\n        start, train_set_size, rank, world_size\n    )\n    rank_eval_start, rank_eval_stop = distribute_to_rank(\n        train_set_size, eval_stop, rank, world_size\n    )\n    rank_test_start, rank_test_stop = distribute_to_rank(\n        eval_stop, num_data_points, rank, world_size\n    )\n    # wrap up splits into a dict\n    train_split_args = dict(\n        start=rank_train_start, stop=rank_train_stop, batch_size=batch_size\n    )\n    eval_split_args = dict(\n        start=rank_eval_start, stop=rank_eval_stop, batch_size=batch_size\n    )\n    test_split_args = dict(",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:211-242"
    },
    "809": {
        "file_id": 23,
        "content": "Computing split points for training and evaluation data sets based on the specified splits. Distributing the data to ranks according to the world size. Wrapping up the splits into a dictionary with start, stop, and batch_size parameters.",
        "type": "comment"
    },
    "810": {
        "file_id": 23,
        "content": "        start=rank_test_start, stop=rank_test_stop, batch_size=batch_size\n    )\n    if text_conditioned:\n        # add the text-conditioned args to a unified dict\n        reader_args = dict(\n            text_conditioned=text_conditioned,\n            image_reader=image_reader,\n        )\n        train_split_args = dict(**reader_args, **train_split_args)\n        eval_split_args = dict(**reader_args, **eval_split_args)\n        test_split_args = dict(**reader_args, **test_split_args)\n        train = PriorEmbeddingDataset(**train_split_args)\n        val = PriorEmbeddingDataset(**eval_split_args)\n        test = PriorEmbeddingDataset(**test_split_args)\n    else:\n        # add the non-conditioned args to a unified dict\n        reader_args = dict(\n            text_conditioned=text_conditioned,\n            image_reader=image_reader,\n            text_reader=text_reader,\n        )\n        train_split_args = dict(**reader_args, **train_split_args)\n        eval_split_args = dict(**reader_args, **eval_split_args)\n        test_split_args = dict(**reader_args, **test_split_args)",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:243-271"
    },
    "811": {
        "file_id": 23,
        "content": "Code is creating a PriorEmbeddingDataset for train, validation, and test datasets based on given arguments. If text_conditioned, it creates separate dictionaries for each dataset and passes them to the PriorEmbeddingDataset class; otherwise, it adds additional non-conditioned arguments for the same process.",
        "type": "comment"
    },
    "812": {
        "file_id": 23,
        "content": "        train = PriorEmbeddingDataset(**train_split_args)\n        val = PriorEmbeddingDataset(**eval_split_args)\n        test = PriorEmbeddingDataset(**test_split_args)\n    # true batch size is specifed in the PriorEmbeddingDataset\n    train_loader = DataLoader(train, batch_size=None)\n    eval_loader = DataLoader(val, batch_size=None)\n    test_loader = DataLoader(test, batch_size=None)\n    return train_loader, eval_loader, test_loader",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/prior_loader.py:273-282"
    },
    "813": {
        "file_id": 23,
        "content": "This code creates train, val, and test datasets using PriorEmbeddingDataset with specific args. DataLoaders are created without specifying batch sizes, so the true batch size is determined in PriorEmbeddingDataset. The loaders and datasets are returned for further processing.",
        "type": "comment"
    },
    "814": {
        "file_id": 24,
        "content": "/dalle2_pytorch/dataloaders/simple_image_only_dataloader.py",
        "type": "filepath"
    },
    "815": {
        "file_id": 24,
        "content": "This code defines a Dataset class and get_images_dataloader function for loading image data. The Dataset class initializes with a folder path, image size, and extensions to consider. The get_images_dataloader function returns a DataLoader object for the specified folder with optional parameters like batch size, shuffle, cycle_dl, and pin_memory.",
        "type": "summary"
    },
    "816": {
        "file_id": 24,
        "content": "from pathlib import Path\nimport torch\nfrom torch.utils import data\nfrom torchvision import transforms, utils\nfrom PIL import Image\n# helpers functions\ndef cycle(dl):\n    while True:\n        for data in dl:\n            yield data\n# dataset and dataloader\nclass Dataset(data.Dataset):\n    def __init__(\n        self,\n        folder,\n        image_size,\n        exts = ['jpg', 'jpeg', 'png']\n    ):\n        super().__init__()\n        self.folder = folder\n        self.image_size = image_size\n        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n        self.transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.RandomHorizontalFlip(),\n            transforms.CenterCrop(image_size),\n            transforms.ToTensor()\n        ])\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, index):\n        path = self.paths[index]\n        img = Image.open(path)\n        return self.transform(img)\ndef get_images_dataloader(\n    folder,\n    *,",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/simple_image_only_dataloader.py:1-47"
    },
    "817": {
        "file_id": 24,
        "content": "This code defines a Dataset class and get_images_dataloader function for loading image data. The Dataset class initializes with a folder path, image size, and extensions to consider. It uses transforms to apply resizing, horizontal flipping, centercropping, and converting images to tensors. The get_images_dataloader function returns a data loader object for the specified folder.",
        "type": "comment"
    },
    "818": {
        "file_id": 24,
        "content": "    batch_size,\n    image_size,\n    shuffle = True,\n    cycle_dl = True,\n    pin_memory = True\n):\n    ds = Dataset(folder, image_size)\n    dl = data.DataLoader(ds, batch_size = batch_size, shuffle = shuffle, pin_memory = pin_memory)\n    if cycle_dl:\n        dl = cycle(dl)\n    return dl",
        "type": "code",
        "location": "/dalle2_pytorch/dataloaders/simple_image_only_dataloader.py:48-59"
    },
    "819": {
        "file_id": 24,
        "content": "This function takes parameters such as folder, batch size, image size, shuffle, cycle_dl, and pin_memory. It creates a dataset from the provided folder using a given image size. Then, it uses DataLoader to create a data loader with the specified batch size, shuffle, and pin memory settings. If cycle_dl is True, it applies cyclic permutations to the data loader. Finally, it returns the data loader.",
        "type": "comment"
    }
}